{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61ccadd6",
   "metadata": {},
   "source": [
    "# Smoothing - Filtering - Forcasting: Looking at moving averages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9871d3c",
   "metadata": {},
   "source": [
    "## Intro\n",
    "In this Notebook we will take a look at different ways to compute moving averages (aka rolling means aka rolling averages aka ...) for a simple dataset.\n",
    "\n",
    "The target is to get a visual understanding on: \n",
    "- The general idea behind MA\n",
    "- How MA are computed\n",
    "- The differences between\n",
    "    - moving average\n",
    "    - weighted moving average\n",
    "    - exponentially weighted moving average \n",
    "\n",
    "Another aim of this Notebook is to show why moving averages are important and to give some application examples.\n",
    "\n",
    "This Notebook is more \"follow along and watch it unfold\" then do-it-yourself, but feel free to try-out and adjust the code to your liking.\n",
    "\n",
    "A large part of this Notebook is code used to generate the animations. It's not necessary to go through that in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c70091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only run if necessary:\n",
    "#!brew install ffmpeg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87e09e95",
   "metadata": {},
   "source": [
    "## Let's get started!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d7335f7",
   "metadata": {},
   "source": [
    "\n",
    "First we start by importing the relevant libraries. Here we mostly use basic stuff, additionally we use matplotlib.animation to generate animations and Ipython.display.Video to show the generated animation. \n",
    "\n",
    "Working with Timeseries / signals, Statsmodel and Scipy are generally good starting points. Here, we only import statsmodels.api to generate the dataset we are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae45a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "#Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import Video\n",
    "\n",
    "#Statistics\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#General\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bdd6e9e",
   "metadata": {},
   "source": [
    "## Helping functions the backbone of this notebook\n",
    "As mentioned in the Intro, you don't have to go through them in detail."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d065c52a",
   "metadata": {},
   "source": [
    "### Colors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d7c9979",
   "metadata": {},
   "source": [
    "Most important for this is, obviously, getting the right colors. So lets start by setting them up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb3970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neufische colors\n",
    "NF_ORANGE = '#ff5a36'\n",
    "NF_BLUE = '#163251'\n",
    "\n",
    "def _color_palette(n_cols):\n",
    "    \"\"\"This generates a palette with N colors, to ensure every relevant point has it's specific color.  \n",
    "    The colors are ligher shades of the neuefische blue.\n",
    "\n",
    "    Args:\n",
    "        n_cols (int): number of returned colors. If more then 20 colors are requested, the first ones will be the same grey.\n",
    "\n",
    "    Returns:\n",
    "        List: List of Colors in Hex\n",
    "    \"\"\"\n",
    "    dark_colors=sns.color_palette(\"light:#163251\", as_cmap=False,n_colors=9).as_hex() #NF_blue basis, palette used for the darker shades\n",
    "    bright_colors = sns.color_palette(\"light:#9ea9b6\", as_cmap=False,n_colors=15).as_hex() #Add some lighter shades, start shade is overlapping with dark\n",
    "    colors=bright_colors+dark_colors[4:]\n",
    "    if(n_cols>20):\n",
    "        colors=[\"#f0f1f2\"]*(n_cols-20)+colors\n",
    "    return colors[-n_cols:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e841a537",
   "metadata": {},
   "source": [
    "What we do here is setting up an function that basically returns a list of hexcodes for as many colors as we want. To keep things elegant, we are using lighter and darker shades of Blue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1a091c7",
   "metadata": {},
   "source": [
    ">__Exercise__: Generate color palettes with 3,5,10 and 30 Colors and visualize them with ```    sns.color_palette() ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488c3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,3,5,10,30]:\n",
    "    display(sns.color_palette(_color_palette(i)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1149a26",
   "metadata": {},
   "source": [
    "### Helper functions\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36dac4b5",
   "metadata": {},
   "source": [
    "Next lets define some helpful functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3be4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _slicer(df):\n",
    "    \"\"\"Generator function to slice DataFrames\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Given Data\n",
    "\n",
    "    Yields:\n",
    "        IteratorObject: The slices of the input data. First slice is the first row, second slice the first and second row third slice the first three rows etc.\n",
    "    \"\"\"\n",
    "    for i in range(len(df)):\n",
    "        yield df.iloc[:i+1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de35675b",
   "metadata": {},
   "source": [
    "The slices of the input data. First slice is the first row, second slice the first and second row third slice the first three rows etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4475f78",
   "metadata": {},
   "source": [
    ">__Exercise__: Create a simple dataframe and use _slicer() to generate one slice (tip: use next()) and all slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d6c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\"I packed my bag and in it I put:\":[\"a fish\",\"some data\",\"a coach\",\"a PC\",\"and a python\"]})\n",
    "next(_slicer(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7507d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "for slice in _slicer(df):\n",
    "    display(slice)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc5997c4",
   "metadata": {},
   "source": [
    "### Computing the rolling mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77949573",
   "metadata": {},
   "source": [
    "Here it gets more insteresting the _weights()-functions creates weights to compute a mean for different objectives(but we'll get to that later).\n",
    "The weights here are all getting normalized already, so that the mean functions can directly apply and sum them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ab0ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _weights(df,dist,alpha=0.6):\n",
    "    \"\"\"Function generates the weights for computing the averages\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The Data the list weights are generated (number of weight = length of data)\n",
    "        dist (string): The distribution of weights. Possibilities are [\"unif\",\"triang\",\"exp\"] for uniform, triangular and exponential distributions.\n",
    "        alpha (float, optional): Exponential smoothing factor in case the \"exp\" dist is used. Must be between 0 and 1.   Defaults to 0.6.\n",
    "\n",
    "    Returns:\n",
    "        [np.array]: [list of weights]\n",
    "    \"\"\"\n",
    "    if dist==\"unif\":\n",
    "        weights=np.array([1]*len(df))  #1 1 1 1\n",
    "    \n",
    "    if dist==\"triang\":\n",
    "        weights=np.arange(1,len(df)+1) #1 2 3 4 \n",
    "\n",
    "    if dist==\"exp\":\n",
    "        weights=np.flip(np.array([alpha*(1-alpha)**i for i in range(len(df))]))\n",
    "    \n",
    "    weights=weights/np.sum(weights)\n",
    "    return weights    \n",
    "\n",
    "def _mean_unif(df):\n",
    "    weights=_weights(df,\"unif\")\n",
    "    return np.sum(np.array(df)*weights)\n",
    "\n",
    "def _mean_triang(df):\n",
    "    weights=_weights(df,\"triang\")\n",
    "    return np.sum(np.array(df)*weights)\n",
    "\n",
    "def _mean_exp(df,exp_alpha):\n",
    "    weights=_weights(df,\"exp\",exp_alpha)\n",
    "    return float(np.sum(np.array(df).ravel()*weights))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af8e2b9a",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e022e034",
   "metadata": {},
   "source": [
    "To evaluate the performance of the moving averages we are going to compute we use the rmse. For this we use the following function, as it is well suited to deal with NA values (i.e. it just ignores those)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2f1170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rmse(y_true,y_pred):\n",
    "    return(np.sqrt(np.square(y_true - y_pred).mean()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "480dbebc",
   "metadata": {},
   "source": [
    "### Precompute all required data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dffa7302",
   "metadata": {},
   "source": [
    "\n",
    "In the next function, all the rolling means and the respective RMSE values are computed. It will be much easier to understand how this is done after you went through the whole notebook. For those of you who can't wait:\n",
    "All that you will have to do in the end is to use:\n",
    "```python\n",
    "    df.value.rolling(window_size).mean() #compute rolling mean\n",
    "    df.value.ewm(alpha=exp_alpha).mean() #compute exponentially weighted mean\n",
    "```                        \n",
    "Everything else is only for visualisation purposes and to make the educational example of how different customized weight-distributions can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f3dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rolling_data(df,window_size,exp_alpha):\n",
    "\n",
    "    df_precomp=df.assign(noiseless=df.ts*10/len(df),\n",
    "                        pandas_rollmean=df.value.rolling(window_size).mean(),\n",
    "                        pandas_ewma=df.value.ewm(alpha=exp_alpha).mean(),\n",
    "                        custom_rollmean_unif=df.value.rolling(window_size).apply(lambda x: _mean_unif(x)),\n",
    "                        custom_rollmean_triang=df.value.rolling(window_size).apply(lambda x: _mean_triang(x)))\n",
    "\n",
    "    \n",
    "    #compute the custom rolling ewma\n",
    "    ewma=[]\n",
    "    for s in _slicer(df_precomp):\n",
    "        ewma.append(_mean_exp(s.value,exp_alpha))\n",
    "    df_precomp=df_precomp.assign(custom_ewma=ewma)\n",
    "\n",
    "    # prepare storage for metrics\n",
    "    metric_store={\"rmse_signal\":[],\"rmse_pandas_rollmean\":[],\"rmse_pandas_ewma\":[],\"rmse_custom_rollmean_unif\":[],\"rmse_custom_rollmean_unif_noiseless\":[],\"rmse_custom_rollmean_triang\":[],\"rmse_custom_rollmean_triang_noiseless\":[],\"rmse_custom_ewma\":[],\"rmse_custom_ewma_noiseless\":[]}\n",
    "\n",
    "    # compute the metrics for each cumulative slice (basically the metric \"up to \") and store them in the metric_store\n",
    "    for s in _slicer(df_precomp):\n",
    "        metric_store[\"rmse_signal\"].append(                             _rmse(s.noiseless,s.value))\n",
    "        metric_store[\"rmse_pandas_rollmean\"].append(                    _rmse(s.value,s.pandas_rollmean))\n",
    "        metric_store[\"rmse_pandas_ewma\"].append(                        _rmse(s.value,s.pandas_ewma))\n",
    "        metric_store[\"rmse_custom_rollmean_unif\"].append(               _rmse(s.value, s.custom_rollmean_unif))\n",
    "        metric_store[\"rmse_custom_rollmean_unif_noiseless\"].append(     _rmse(s.noiseless, s.custom_rollmean_unif))\n",
    "        metric_store[\"rmse_custom_rollmean_triang\"].append(             _rmse(s.value, s.custom_rollmean_triang))\n",
    "        metric_store[\"rmse_custom_rollmean_triang_noiseless\"].append(   _rmse(s.noiseless, s.custom_rollmean_triang))\n",
    "        metric_store[\"rmse_custom_ewma\"].append(                        _rmse(s.value, s.custom_ewma))\n",
    "        metric_store[\"rmse_custom_ewma_noiseless\"].append(              _rmse(s.noiseless, s.custom_ewma))\n",
    "\n",
    "    # turn metric_store into df and append its columns \n",
    "    df_precomp=pd.concat([df_precomp,pd.DataFrame(metric_store)]\n",
    "                         ,axis=1)\n",
    "    \n",
    "    # return result\n",
    "    return df_precomp\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91310956",
   "metadata": {},
   "source": [
    "### Animation time!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61ccc141",
   "metadata": {},
   "source": [
    "The animations are generated in 4 *easy* steps:\n",
    "1. Create ```animate()``` function, that draws the frame you want to show in the animation. The function should at least take a number as an argument (here i). This number is the Frame of the animation, so calls with different numbers will subsequently build up the animation.\n",
    "2. Use ```animation.FuncAnimation()```. This will call the animate function once for each frame in ```frames``` (actually twice for the first frame but nvm) with the additional arguments given in ```fargs```\n",
    "3. Use the ```animation.FFMPEGWriter()``` function to set stuff like fps, bitrate etc.\n",
    "4. Use ```ani.save()``` to write the animation to file    \n",
    "\n",
    "Steps 2-4 are performed within ```generate_animation()```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f41521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate(i, ax, data, smooth_type, size, exp_alpha,noiseless=False):\n",
    "    \"\"\"The main animation function. Each frame is drawn individually with this function.\n",
    "\n",
    "    Args:\n",
    "        i (int): Number of frame in the animation\n",
    "        ax (matplotlib.axes): The ax object used to draw the frame\n",
    "        data (DataFrame): The Data to draw, ie. the timeseries\n",
    "        smooth_type (string): One of ['unif','triang','exp'], if unif is chosen, only that line is drawn. For 'triang' its 'unif' and 'triang' and for 'exp' its all three\n",
    "        size (int): Window-size used for the rolling average\n",
    "        exp_alpha (float): the exponential smoothing factor for smooth_type 'exp'\n",
    "    \"\"\"\n",
    "    \n",
    "    # compute the relevant means\n",
    "    df_precomp=data\n",
    "    df_precomp_up_to=df_precomp[:i+size]\n",
    "    \n",
    "    if(smooth_type==\"unif\"):\n",
    "        precision=1\n",
    "        df_precomp_window=df_precomp_up_to.iloc[-size:]\n",
    "        current=\"custom_rollmean_unif\"\n",
    "    if(smooth_type==\"triang\"):\n",
    "        precision=1\n",
    "        df_precomp_window=df_precomp_up_to.iloc[-size:]\n",
    "        current=\"custom_rollmean_triang\"\n",
    "    if(smooth_type==\"exp\"):\n",
    "        precision=2\n",
    "        df_precomp_window=df_precomp_up_to\n",
    "        current=\"custom_ewma\"\n",
    "    \n",
    "    weights=_weights(df_precomp_window,smooth_type,exp_alpha)\n",
    "    \n",
    "    colors=_color_palette(len(df_precomp_window))\n",
    "    ax.clear()\n",
    "\n",
    "    font = {'family': 'sans-serif',\n",
    "            'color':  'black',\n",
    "            'weight': 'normal',\n",
    "            'size': 16}\n",
    "\n",
    "    ax.xaxis.label.set_size(14)\n",
    "    ax.yaxis.label.set_size(14)\n",
    "\n",
    "    ax.grid(True)\n",
    "    ax.tick_params(labelcolor='dimgrey',\n",
    "                   labelsize='medium',\n",
    "                   length=7,\n",
    "                   color='lightgrey',\n",
    "                   direction=\"out\",\n",
    "                   left=True,\n",
    "                   bottom=True)\n",
    "\n",
    "    ax.set_title('Rolling mean',\n",
    "                 pad=30,\n",
    "                 fontdict=font)\n",
    "\n",
    "    ax.set_xlabel('Timestep',\n",
    "                  labelpad=20,\n",
    "                  color=\"dimgrey\")\n",
    "\n",
    "    ax.set_ylabel('Signal',\n",
    "                  labelpad=20,\n",
    "                  color=\"dimgrey\")\n",
    "    ax.set_xlim(-1,len(df_precomp) +5)\n",
    "    ax.set_ylim(-3,12)\n",
    "    \n",
    "    #Original data\n",
    "    sns.lineplot(x=df_precomp.ts,\n",
    "                 y=df_precomp.value,\n",
    "                 ax=ax,\n",
    "                 ci=None,\n",
    "                 color=NF_BLUE,\n",
    "                 label=\"Original Data\")\n",
    "    if noiseless:\n",
    "        plt.plot(df_precomp.ts,\n",
    "                 df_precomp.noiseless,\n",
    "                 \"--\",\n",
    "                 color=NF_BLUE,)        \n",
    "        \n",
    "        \n",
    "    # Output Rolling Error + Mean line\n",
    "    # stacked lines!\n",
    "\n",
    "    plt.text(x=3,y=7.5,s=\"RMSE unif:        {:.0%}\".format(df_precomp_up_to.iloc[-1].rmse_custom_rollmean_unif),rotation=00,ha=\"left\",size=10,color=NF_ORANGE,alpha=0.5,family=\"monospace\")\n",
    "    if(smooth_type in [\"exp\",\"triang\"]):\n",
    "        plt.text(x=3,y=7.0,s=\"RMSE triang:      {:.0%}\".format(df_precomp_up_to.iloc[-1].rmse_custom_rollmean_triang),rotation=00,ha=\"left\",size=10,color=NF_ORANGE,alpha=0.8,family=\"monospace\")\n",
    "    if(smooth_type == \"exp\"):\n",
    "        plt.text(x=3,y=6.5,s=\"RMSE exp:         {:.0%}\".format(df_precomp_up_to.iloc[-1].rmse_custom_ewma),rotation=00,ha=\"left\",size=10,color=NF_ORANGE,alpha=1,family=\"monospace\")\n",
    "    \n",
    "    if noiseless:\n",
    "        plt.text(x=3,y=8.5,s=\"RMSE signal:      {:.0%}\".format(df_precomp_up_to.iloc[-1].rmse_signal),rotation=00,ha=\"left\",size=10,color=NF_BLUE,alpha=1,family=\"monospace\")\n",
    "        plt.text(x=3,y=5.5,s=\"RMSE unif true:   {:.0%}\".format(df_precomp_up_to.iloc[-1].rmse_custom_rollmean_unif_noiseless),rotation=00,ha=\"left\",size=10,color=NF_ORANGE,alpha=0.5,family=\"monospace\")\n",
    "        if(smooth_type in [\"exp\",\"triang\"]):\n",
    "            plt.text(x=3,y=5.0,s=\"RMSE triang true: {:.0%}\".format(df_precomp_up_to.iloc[-1].rmse_custom_rollmean_triang_noiseless),rotation=00,ha=\"left\",size=10,color=NF_ORANGE,alpha=0.8,family=\"monospace\")\n",
    "        if(smooth_type == \"exp\"):\n",
    "            plt.text(x=3,y=4.5,s=\"RMSE exp true:    {:.0%}\".format(df_precomp_up_to.iloc[-1].rmse_custom_ewma_noiseless),rotation=00,ha=\"left\",size=10,color=NF_ORANGE,alpha=1,family=\"monospace\")\n",
    "    \n",
    "    # Rolling mean line\n",
    "    sns.lineplot(x=df_precomp_up_to.ts,\n",
    "                 y=df_precomp_up_to.custom_rollmean_unif,\n",
    "                 ax=ax,\n",
    "                 ci=None,\n",
    "                 color=NF_ORANGE,\n",
    "                 alpha=0.5,\n",
    "                 label=\"Uniformly weighted mean\")\n",
    "    if(smooth_type in [\"exp\",\"triang\"]):\n",
    "        sns.lineplot(x=df_precomp_up_to.ts,\n",
    "                    y=df_precomp_up_to.custom_rollmean_triang,\n",
    "                    ax=ax,\n",
    "                    ci=None,\n",
    "                    color=NF_ORANGE,\n",
    "                    alpha=0.8,\n",
    "                    label=\"triangular weighted mean\")\n",
    "    \n",
    "    if(smooth_type == \"exp\"):\n",
    "        sns.lineplot(x=df_precomp_up_to.ts,\n",
    "                 y=df_precomp_up_to.custom_ewma,\n",
    "                 ax=ax,\n",
    "                 ci=None,\n",
    "                 color=NF_ORANGE,\n",
    "                 alpha=1,\n",
    "                 label=\"exponentialy weighted mean\")        \n",
    "    \n",
    "    ## Plot vertical lines for window points\n",
    "    plt.vlines(x=df_precomp_window.ts,\n",
    "                ymin=0,\n",
    "                ymax=df_precomp_window.value,\n",
    "                color=colors,\n",
    "                linestyles=\"dotted\")\n",
    "\n",
    "    ## Rolling mean current value\n",
    "    sns.scatterplot(data=df_precomp_up_to.iloc[-1:],\n",
    "                    x=\"ts\",\n",
    "                    y=current,\n",
    "                    color=NF_ORANGE,\n",
    "                    marker=\"X\",\n",
    "                    s=300,\n",
    "                    alpha=1)                \n",
    "\n",
    "    # Little horozontal helper line\n",
    "    plt.hlines(y=df_precomp_up_to[current].iloc[-1],\n",
    "                xmin=df_precomp_up_to.ts.iloc[-1],\n",
    "                xmax=df_precomp_up_to.ts.iloc[-1]+4,\n",
    "                color=NF_BLUE)            \n",
    "    \n",
    "    # Points used for smothing\n",
    "    plt.scatter(x=df_precomp_window.ts,\n",
    "                y=df_precomp_window.value,\n",
    "                #color=NF_BLUE,\n",
    "                color=colors,\n",
    "                s=400,\n",
    "                marker=\".\"\n",
    "                )\n",
    "\n",
    "    # lines and points that make up the mean\n",
    "    plt.bar(df_precomp_window.ts,\n",
    "            (df_precomp_window.value*weights),\n",
    "            color=colors,\n",
    "            )\n",
    "                \n",
    "    # weights distribution under points\n",
    "    plt.bar(df_precomp_window.ts, \n",
    "            [-10*i for i in weights],\n",
    "            color=\"grey\", alpha=0.2)\n",
    "    \n",
    "\n",
    "    # weight labels in perc\n",
    "    for i,v in enumerate(df_precomp_window.ts):\n",
    "        #plt.text(x=v,y=-1,s=\"{:.3%}\".format(weights[i]),rotation=90,ha=\"center\",va=\"top\",size=8)\n",
    "        plt.text(x=v,y=-1,s=f\"{round(100*weights[i],precision)}%\",rotation=90,ha=\"center\",va=\"top\",size=8)\n",
    "        \n",
    "    \n",
    "    ## stacked Bar Plot summary distribution\n",
    "    for i in range(len(df_precomp_window)):\n",
    "        plt.bar(x=df_precomp_window.ts.iloc[-1]+3,\n",
    "                height=(df_precomp_window.value*weights).iloc[i],\n",
    "                bottom=(df_precomp_window.value*weights)[:i].sum(),\n",
    "                edgecolor=\"lightgrey\",\n",
    "                linewidth=1,\n",
    "                width=2,\n",
    "                color=colors[i])\n",
    "        \n",
    "    ## Plot legend\n",
    "    plt.legend(loc=(0.03,0.8), frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb0cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_animation(name,data,smooth_type,window_size,alpha,frames,fps,noiseless=False):\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    \n",
    "    ani = animation.FuncAnimation(fig,\n",
    "                        animate,\n",
    "                        fargs=[ax,data,smooth_type,window_size,alpha,noiseless],\n",
    "                        frames=np.arange(0, frames-window_size+1, 1),\n",
    "                        interval=1\n",
    "                        )\n",
    "\n",
    "    writer = animation.FFMpegWriter(\n",
    "        fps=fps, metadata=dict(artist='neuefische'), bitrate=1800)\n",
    "\n",
    "    ani.save(name,\n",
    "            writer=writer,\n",
    "            dpi=200)\n",
    "    plt.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b151f4eb",
   "metadata": {},
   "source": [
    "# Setup done, lets use it!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "104e4924",
   "metadata": {},
   "source": [
    "First we need some data, so lets generate a beautiful test signal and create a function to plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f05e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_plot(x,y,z=None):\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "    font = {'family': 'sans-serif',\n",
    "            'color':  'black',\n",
    "            'weight': 'normal',\n",
    "            'size': 16}\n",
    "\n",
    "    ax.xaxis.label.set_size(14)\n",
    "    ax.yaxis.label.set_size(14)\n",
    "\n",
    "    ax.grid(True)\n",
    "    ax.tick_params(labelcolor='dimgrey',\n",
    "                    labelsize='medium',\n",
    "                    length=7,\n",
    "                    color='lightgrey',\n",
    "                    direction=\"out\",\n",
    "                    left=True,\n",
    "                    bottom=True)\n",
    "\n",
    "    ax.set_title('Generate a test data Signal',\n",
    "                    pad=30,\n",
    "                    fontdict=font)\n",
    "\n",
    "    ax.set_xlabel('timestamp',\n",
    "                    labelpad=20,\n",
    "                    color=\"dimgrey\")\n",
    "\n",
    "    ax.set_ylabel('Signal',\n",
    "                    labelpad=20,\n",
    "                    color=\"dimgrey\")\n",
    "\n",
    "    ax.set_xlim(-0,60)\n",
    "    ax.set_ylim(0,12)\n",
    "    sns.lineplot(x=x,y=y,color=NF_BLUE,ax=ax)\n",
    "    sns.lineplot(x=x,y=y,color=NF_BLUE,ax=ax)\n",
    "    sns.scatterplot(x=x,y=y,color=NF_BLUE,marker=\"o\",s=150,ax=ax)\n",
    "    if z is None:\n",
    "        pass\n",
    "    else:\n",
    "        sns.lineplot(x=x,y=z,color=NF_ORANGE,ax=ax)        \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c36d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate random data\n",
    "samples=60\n",
    "np.random.seed(13)\n",
    "x=np.arange(samples)\n",
    "y=sm.tsa.ArmaProcess(ar=[1,-0.8]).generate_sample(nsample=samples) + x*10/samples \n",
    "\n",
    "plt_ax=signal_plot(x,y)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c94f0240",
   "metadata": {},
   "source": [
    "Wait a second. Thats not a beautiful signal, thats wiggly! Let's use something to smooth things over a little.\n",
    "\n",
    " How about we add to the plot... the average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a2a75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt_ax=signal_plot(x,y,pd.DataFrame(y).mean().tolist()*len(x))\n",
    "plt_ax=signal_plot(x,y,[y.mean()]*len(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cac491c",
   "metadata": {},
   "source": [
    "No. How about we add to the plot... the moving average?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "808f8d26",
   "metadata": {},
   "source": [
    "## Moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a16dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_ax=signal_plot(x,y,pd.DataFrame(y).rolling(9).mean()[0].tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9593e31b",
   "metadata": {},
   "source": [
    "That looks much better! But what is this orange line? Lets use our animation to find out whats behind that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcefaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MA and Animation settings\n",
    "name=\"visualisations/MA_uniform.mp4\"     # name of generated animation\n",
    "smooth_type=\"unif\"  # one of: unif, triang, exp\n",
    "\n",
    "window_size=9       # size of rolling window, i.e. numbers of points used\n",
    "alpha=0.4           # smoothing factor for exp (0,1)\n",
    "samples=60          # numbers of sample in test frame\n",
    "fps=3               # animation frames per second\n",
    "\n",
    "\n",
    "#Generate random data\n",
    "np.random.seed(13)\n",
    "x=np.arange(samples)\n",
    "y=sm.tsa.ArmaProcess(ar=[1,-0.8]).generate_sample(nsample=samples) + x*10/samples \n",
    "\n",
    "#process data\n",
    "data = pd.DataFrame({\"ts\":x,\"value\":y})\n",
    "df_precomputed_data=compute_rolling_data(data,window_size,alpha)\n",
    "\n",
    "#make the animation\n",
    "generate_animation(name,df_precomputed_data,smooth_type,window_size,alpha,samples,fps)\n",
    "\n",
    "#show the result\n",
    "Video(name, width=1024)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c77a3b4b",
   "metadata": {},
   "source": [
    "Yes! It worked :) \n",
    "\n",
    "Now, let's have a closer look. First, the blue line. This is the input dataseries we are analyzing. Next, look at moving window: we selected a size of 9 so its 9 points that are moving through the data to compute the mean at each step (hence, moving average). Those nine points are marked with colored big dots and a matching dotted line to the x axis. Below the axis you see the weight that each point is given. As we are just using a mean here, each of the 9 points has an uniform weight of 1/9 as shown by the grey bars and the percentage number (1/9 = 11.1%). \n",
    "\n",
    "The colored bars above the x-axis show the contribution of the window points (weight multiplied with their value). On the right side, next to the distributions, those contributions are stacked. If you add all of them up, you end up with the orange x, the computed rolling average. Easy, right?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc3b8c98",
   "metadata": {},
   "source": [
    "## Triangular weighted moving average"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a75dc258",
   "metadata": {},
   "source": [
    "In the last example, we used mean on the window-points, so all points had the same weight. But in time-series often it makes more sense to put more weight to the more recent points and less weight to the once further in the past. For example, if you have a time-series from your daily measurements on the scale. It makes sense that the measurement of today is closer to the measurement from yesterday then the measurement of the day befor that. (unless you take seasonality into account because we typically eat more on weekends but we'll get to that later).\n",
    "\n",
    "So lets change the weights distribution from uniform to triangular: the oldest of the window points gets the weight one, second oldest two etc.\n",
    "\n",
    " Lets see how this affects the moving average (and for a better comparison, we just stack it on top of the previous animation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82528c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"visualisations/MA_triang.mp4\"     # name of generated animation\n",
    "smooth_type=\"triang\"   # one of: unif, triang, exp\n",
    "\n",
    "window_size=9       # size of rolling window, i.e. numbers of points used\n",
    "alpha=0.4           # smoothing factor for exp (0,1)\n",
    "samples=60          # numbers of sample in test frame\n",
    "fps=3               # animation frames per second\n",
    "\n",
    "\n",
    "#Generate random data\n",
    "np.random.seed(13)\n",
    "x=np.arange(samples)\n",
    "y=sm.tsa.ArmaProcess(ar=[1,-0.8]).generate_sample(nsample=samples) + x*10/samples \n",
    "\n",
    "#process data\n",
    "data = pd.DataFrame({\"ts\":x,\"value\":y})\n",
    "df_precomputed_data=compute_rolling_data(data,window_size,alpha)\n",
    "\n",
    "#make the animation\n",
    "generate_animation(name,df_precomputed_data,smooth_type,window_size,alpha,samples,fps)\n",
    "\n",
    "#show the result\n",
    "Video(name, width=1024)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9fb5682d",
   "metadata": {},
   "source": [
    "In general it looks pretty similar. But we can clearly see the different distribution of the weights by looking at the grey bars and the attached percentage numbers (again, the numbers are  scaled down from [1...9] ot ensure that their sum is one).\n",
    "\n",
    "As we put more weight on the most recent data points, this triangular weighted moving average follows the originial signal closer, but still shows a good smoothing. We can see that not just by eye-balling it, but by looking at the RMSE for both lines that are also shown in the plot. The number given in the animation is updating so its always the RMSE up to the current point. As the RMSE is smaller for the triangular line, we can see that this is a closer fit to the original signal. Nice!\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d62ec00",
   "metadata": {},
   "source": [
    "## Exponentialy weighted moving average"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cec4c6e8",
   "metadata": {},
   "source": [
    "What else can we do? In the previous examples, we used a fixed window size: we always used nine points to compute the average. But if we adjust the weights anyway, we dont have to restrict ourselfs to fixed windows. \n",
    "\n",
    "Let's see how that looks and what it means!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f487f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"visualisations/MA_exp.mp4\"     # name of generated animation\n",
    "smooth_type=\"exp\"   # one of: unif, triang, exp\n",
    "\n",
    "window_size=9       # size of rolling window, i.e. numbers of points used\n",
    "alpha=0.4           # smoothing factor for exp (0,1)\n",
    "samples=60          # numbers of sample in test frame\n",
    "fps=3               # animation frames per second\n",
    "\n",
    "#Generate random data\n",
    "np.random.seed(13)\n",
    "x=np.arange(samples)\n",
    "y=sm.tsa.ArmaProcess(ar=[1,-0.8]).generate_sample(nsample=samples) + x*10/samples \n",
    "\n",
    "#process data\n",
    "data = pd.DataFrame({\"ts\":x,\"value\":y})\n",
    "df_precomputed_data=compute_rolling_data(data,window_size,alpha)\n",
    "\n",
    "#make the animation\n",
    "generate_animation(name,df_precomputed_data,smooth_type,window_size,alpha,samples,fps)\n",
    "\n",
    "#show the result\n",
    "Video(name, width=1024)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c23f18f",
   "metadata": {},
   "source": [
    "As you can see, all the points from the history are kept within the window! But to not have an overwhelming impact of the past values, we make sure that the weight we put on points further in the past is decaying quite fast. For example, the weight for the 15-points back is already down to 0.03\\%. But it's still (slightly) contributing! \n",
    "\n",
    "What we used here is called: exponentially weighted moving average (EWMA). For most applications where a moving averages can be used, this yields very good results. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "241c85a2",
   "metadata": {},
   "source": [
    "But why is it calles **exponentially** weighted? The name stems from the way the decay in the weights is computed: its an exponential decay thats controlled by the parameter \"alpha\" (in the example we use alpha=0.4).\n",
    "\n",
    "Let's look at how we computed the weights:\n",
    "\n",
    "$w_i\\approx \\alpha * (1-\\alpha)^i$ or in our implementation\n",
    "```python\n",
    "weights = np.array([alpha*(1-alpha)**i for i in range(len(df))]))\n",
    "```\n",
    "So the weight for the most recent point($x_i$, i=0) gets the weight:. \n",
    "\n",
    "$w_0=\\alpha \\cdot (1-\\alpha)^0 = \\alpha=0.4$\n",
    "\n",
    "The point prior to that($x_{i-1}$, i=1) gets the weight:\n",
    "\n",
    "$w_1=\\alpha \\cdot (1-\\alpha)^1 = 0.4*0.6=0.24$\n",
    "\n",
    "The next point ($x_{i-2}$, i=2) gets the weight\n",
    "\n",
    "$w_2=\\alpha \\cdot (1-\\alpha)^2 = 0.4*0.6^2=0.144 $\n",
    "\n",
    "and so on. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29d5f02c",
   "metadata": {},
   "source": [
    "And for those who watched too carefully:\n",
    " Yes for the first points the displayed weight is slightly different because this exponential series only converges to one with infinite members, hence, to compute the mean we actually adjust the weights so that their sum will be one. E.g. for the second point we don't use the weights 0.4 and 0.24 but instead 0.4/(0.6+0.4)=0.625 and 0.24/(0.6+0.4)=0.375. As the series gets longer,the weights are getting closer to $w_i\\approx \\alpha * (1-\\alpha)^i$)\n",
    "\n",
    "To see this look at the 3 most recent weights for series of increasing length with:\n",
    "```python\n",
    "for i in [1,2,5,10,100]:\n",
    "    display(_weights([1]*i,\"exp\",0.4)[-3:])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b9b320",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,2,5,10,100,1000]:\n",
    "    display(_weights([1]*i,\"exp\",0.4)[-3:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "403ed06f",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65e388fc",
   "metadata": {},
   "source": [
    "One of the cases where EWMA (or all the MAs) are used is for smoothing data. So lets see how the different approaches react to outliers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f34daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"visualisations/MA_exp_outlier.mp4\"     # name of generated animation\n",
    "smooth_type=\"exp\"   # one of: unif, triang, exp\n",
    "window_size=9       # size of rolling window, i.e. numbers of points used\n",
    "alpha=0.4           # smoothing factor for exp (0,1)\n",
    "samples=60          # numbers of sample in test frame\n",
    "fps=3               # animation frames per second\n",
    "\n",
    "#Generate random data\n",
    "np.random.seed(13)\n",
    "x=np.arange(samples)\n",
    "y=sm.tsa.ArmaProcess(ar=[1,-0.8]).generate_sample(nsample=samples) + x*10/samples \n",
    "\n",
    "#Introduce \"outlier\"\n",
    "y[15]=20\n",
    "\n",
    "#process data\n",
    "data = pd.DataFrame({\"ts\":x,\"value\":y})\n",
    "df_precomputed_data=compute_rolling_data(data,window_size,alpha)\n",
    "\n",
    "#make the animation\n",
    "generate_animation(name,df_precomputed_data,smooth_type,window_size,alpha,samples,fps)\n",
    "\n",
    "#show the result\n",
    "Video(name, width=1024)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce26d647",
   "metadata": {},
   "source": [
    "As you can see, all of the rolling average models are influenced by the outlier. So if it really is an outlier, it mighty be preferable to replace it with an imputation (suprise, moving averages are ideally to do that as well!), before computing the ma. \n",
    "\n",
    "But if that is not desired, the models are severly smoothing the effect of the outlier. As you can see, EWMA has the smallest RMSE and is overall closest to the signal. However, unsuprisingly this means it's aswell the one most affected by the outlier! \n",
    "If you look at the other hand to the uniform mean, the impact directly at the jumps is the smallest, but the impact lingers for the whole window duration.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1016d9a8",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b07b6cc",
   "metadata": {},
   "source": [
    "Next lets play a little with the smothing parameter (i.e. alpha). We can select values that result in a lot of smoothing(alpha close to zero) to barely any smoothing (alpha close to one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6faf516",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"visualisations/MA_exp_outlier_small.mp4\"     # name of generated animation\n",
    "smooth_type=\"exp\"   # one of: unif, triang, exp\n",
    "\n",
    "window_size=9       # size of rolling window, i.e. numbers of points used\n",
    "alpha=0.05           # smoothing factor for exp (0,1)\n",
    "samples=60          # numbers of sample in test frame\n",
    "fps=3               # animation frames per second\n",
    "\n",
    "\n",
    "#Generate random data\n",
    "np.random.seed(13)\n",
    "x=np.arange(samples)\n",
    "y=sm.tsa.ArmaProcess(ar=[1,-0.8]).generate_sample(nsample=samples) + x*10/samples \n",
    "\n",
    "#Introduce \"outlier\"\n",
    "y[15]=20\n",
    "\n",
    "#process data\n",
    "data = pd.DataFrame({\"ts\":x,\"value\":y})\n",
    "df_precomputed_data=compute_rolling_data(data,window_size,alpha)\n",
    "\n",
    "#make the animation\n",
    "generate_animation(name,df_precomputed_data,smooth_type,window_size,alpha,samples,fps)\n",
    "\n",
    "#show the result\n",
    "Video(name, width=1024)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b03a172",
   "metadata": {},
   "source": [
    "It's much smoother, but then again the error increased quite a bit and especially in the end we see how moving average jsut lags behind the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2903d243",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"visualisations/MA_exp_outlier_large.mp4\"     # name of generated animation\n",
    "smooth_type=\"exp\"   # one of: unif, triang, exp\n",
    "\n",
    "window_size=9       # size of rolling window, i.e. numbers of points used\n",
    "alpha=0.75           # smoothing factor for exp (0,1)\n",
    "samples=60          # numbers of sample in test frame\n",
    "fps=3               # animation frames per second\n",
    "\n",
    "\n",
    "#Generate random data\n",
    "np.random.seed(13)\n",
    "x=np.arange(samples)\n",
    "y=sm.tsa.ArmaProcess(ar=[1,-0.8]).generate_sample(nsample=samples) + x*10/samples \n",
    "\n",
    "#Introduce \"outlier\"\n",
    "y[15]=20\n",
    "\n",
    "#process data\n",
    "data = pd.DataFrame({\"ts\":x,\"value\":y})\n",
    "df_precomputed_data=compute_rolling_data(data,window_size,alpha)\n",
    "\n",
    "#make the animation\n",
    "generate_animation(name,df_precomputed_data,smooth_type,window_size,alpha,samples,fps)\n",
    "\n",
    "#show the result\n",
    "Video(name, width=1024)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab980620",
   "metadata": {},
   "source": [
    "The other extreme: the error is much smaller but the line isn't much smoother then the signal. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86a39096",
   "metadata": {},
   "source": [
    "# Whats the time? Gridsearch time!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a921eea",
   "metadata": {},
   "source": [
    "Up to now, we considered the dataset to be the true data, and the RMSE as an error introduced by deviating from the true data. \n",
    "\n",
    "Let's just assume we now the \"true\" value of the data we are looking at, and we think that those wiggles are just noise. \n",
    "Let's face it: this line \n",
    "```\n",
    "y=sm.tsa.ArmaProcess(ar=[1,-0.8]).generate_sample(nsample=samples) + x*10/samples \n",
    "```\n",
    "looked fishy from the beginning right?!\n",
    "\n",
    "\n",
    "Let's say the latter part is the actual signal and the Arma process part is just noise ontop of that.  \n",
    "\n",
    "For example this could be the situation in a laboratory, where you are testing a new sensor you are developing in an controlled environment. The \"data\" would be the measured signal from the sensor and \"true data\" would be the controlled load of the sensor.\n",
    "\n",
    "Now to develop a good driver for our sensor, we can investigate the optimal smoothing for our EWMA on the laboratory data and compute the RMSE as an error between the smoothing model and the actual true data. \n",
    "\n",
    "How do we optimize this? We use a gridsearch on the parameters! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8efbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"\"     # name of generated animation\n",
    "smooth_type=\"exp\"   # one of: unif, triang, exp\n",
    "\n",
    "window_size=9       # size of rolling window, i.e. numbers of points used\n",
    "alpha=0.75           # smoothing factor for exp (0,1)\n",
    "samples=60          # numbers of sample in test frame\n",
    "fps=3               # animation frames per second\n",
    "\n",
    "#Generate random data\n",
    "np.random.seed(13)\n",
    "x=np.arange(samples)\n",
    "y=sm.tsa.ArmaProcess(ar=[1,-0.8]).generate_sample(nsample=samples) + x*10/samples \n",
    "\n",
    "#Introduce \"outlier\"\n",
    "y[15]=20\n",
    "\n",
    "#process data\n",
    "data = pd.DataFrame({\"ts\":x,\"value\":y})\n",
    "\n",
    "alpha_store=[]\n",
    "rmse_store=[]\n",
    "\n",
    "for alpha in np.arange(0.01,1,0.01):\n",
    "    df_precomputed_data=compute_rolling_data(data,window_size,alpha)\n",
    "    alpha_store.append(alpha)\n",
    "    rmse_store.append(df_precomputed_data.rmse_custom_ewma_noiseless.iloc[-1])\n",
    "\n",
    "arg=np.argmin(np.abs(rmse_store))    \n",
    "best_alpha=alpha_store[arg]\n",
    "best_rmse=rmse_store[arg]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "font = {'family': 'sans-serif',\n",
    "        'color':  'black',\n",
    "        'weight': 'normal',\n",
    "        'size': 16}\n",
    "\n",
    "ax.xaxis.label.set_size(14)\n",
    "ax.yaxis.label.set_size(14)\n",
    "\n",
    "ax.grid(True)\n",
    "ax.tick_params(labelcolor='dimgrey',\n",
    "                labelsize='medium',\n",
    "                length=7,\n",
    "                color='lightgrey',\n",
    "                direction=\"out\",\n",
    "                left=True,\n",
    "                bottom=True)\n",
    "\n",
    "ax.set_title('Gridsearch for optimal smoothing',\n",
    "                pad=30,\n",
    "                fontdict=font)\n",
    "\n",
    "ax.set_xlabel('Alpha',\n",
    "                labelpad=20,\n",
    "                color=\"dimgrey\")\n",
    "\n",
    "ax.set_ylabel('RMSE',\n",
    "                labelpad=20,\n",
    "                color=\"dimgrey\")\n",
    "\n",
    "ax.set_xlim(-0.2,1.2)\n",
    "ax.set_ylim(0,3)\n",
    "\n",
    "for alpha,rmse in zip(alpha_store,rmse_store):\n",
    "    plt.scatter(alpha,rmse,color=NF_BLUE,s=10)\n",
    "plt.scatter(alpha_store[arg],rmse_store[arg],color=NF_ORANGE,label=\"exponential smoothing\")\n",
    "\n",
    "plt.scatter(alpha_store[arg],rmse_store[arg],s=100,marker=\"X\",color=NF_ORANGE)\n",
    "\n",
    "plt.axhline(df_precomputed_data[\"rmse_custom_rollmean_unif_noiseless\"].iloc[-1],color=NF_ORANGE,alpha=0.5, label=\"uniform smoothing\")\n",
    "plt.axhline(df_precomputed_data[\"rmse_custom_rollmean_triang_noiseless\"].iloc[-1],color=NF_ORANGE,alpha=0.8, label=\"triangular smoothing\")\n",
    "plt.axvline(alpha_store[arg],color=\"grey\")\n",
    "plt.axhline(rmse_store[arg],color=\"grey\")\n",
    "plt.legend(frameon=False)\n",
    "print(f\"Best fit with exponential smoothing: alpha={round(alpha_store[arg],2)} and rmse={round(rmse_store[arg],2)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6d90661",
   "metadata": {},
   "source": [
    "As we can see from the plot we get a nice minimum in the Error function At alpha $\\approx$ 0.11.\n",
    "\n",
    " Now lets use this to plot our optimized smoothing model for this application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3225ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"visualisations/MA_uniformexp_opti.mp4\"     # name of generated animation\n",
    "smooth_type=\"exp\"   # one of: unif, triang, exp\n",
    "\n",
    "window_size=9       # size of rolling window, i.e. numbers of points used\n",
    "alpha=best_alpha    # smoothing factor for exp (0,1)\n",
    "samples=60          # numbers of sample in test frame\n",
    "fps=3               # animation frames per second\n",
    "\n",
    "#Generate random data\n",
    "np.random.seed(13)\n",
    "x=np.arange(samples)\n",
    "y=sm.tsa.ArmaProcess(ar=[1,-0.8]).generate_sample(nsample=samples) + x*10/samples \n",
    "\n",
    "#Introduce \"outlier\"\n",
    "y[15]=20\n",
    "\n",
    "#process data\n",
    "data = pd.DataFrame({\"ts\":x,\"value\":y})\n",
    "\n",
    "#recompute data with best alpha\n",
    "df_precomputed_data=compute_rolling_data(data,window_size,best_alpha)\n",
    "    \n",
    "#make the animation\n",
    "generate_animation(name,df_precomputed_data,smooth_type,window_size,best_alpha,samples,fps,noiseless=True)\n",
    "\n",
    "\n",
    "#show the result\n",
    "Video(name, width=1024)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c377910",
   "metadata": {},
   "source": [
    "The value of \"RMSE signal\" is the rmse between the true data (dashed blue line) and the signal (blue line).\n",
    "\n",
    "The first set RMSEs is the error between the smoothed data and the signal (blue line).\n",
    "\n",
    "The second set of RMSEs is the error between the smoothed data and the true data (dashed line). This is what we were optimizing the model for in the gridsearch\n",
    "\n",
    "To be fair we could include different window-sizes for the uniform and triangular smoothing in the in the gridsearch. You can implement that if you want."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cab375da",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4503719d",
   "metadata": {},
   "source": [
    "# Outlook\n",
    "MAs can also be used to forecast data (just leave out the current point). Or to impute missing values / outliers which is quite relevant when processing timeseries with methods that don't allow gaps in the data (e.g. seasonal decomposition). For this it's often beneficial to use symetric windows around the missing value (i.e. the average of the 4 points earlier and 4 points after the gap). \n",
    "\n",
    "In this Notebook three different weight-distributions where shown, but as this can be customised the available options are limitless. For the most used ones see [Pandas](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html) and the built-in signals from [scipy](https://docs.scipy.org/doc/scipy/reference/signal.windows.html#module-scipy.signal.windows)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26e49017",
   "metadata": {},
   "source": [
    "**Don't forget to clear outputs before you commit a Notebook**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4213646",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6426a29efc353468667913ba996e9210bb11ea362e1c6cc99ca53c5c24a75753"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
